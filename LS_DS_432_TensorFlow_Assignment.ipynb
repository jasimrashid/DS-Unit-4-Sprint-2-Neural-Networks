{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_432_TensorFlow_Assignment",
      "provenance": [],
      "collapsed_sections": [
        "s-Tc3ovEyQ9b"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasimrashid/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/LS_DS_432_TensorFlow_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObyHCH8HvHSf",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# *Data Science Unit 4 Sprint 2 Assignment 2*\n",
        "\n",
        "Use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. Please build a baseline classification model then run a few experiments with different optimizers and learning rates. \n",
        "\n",
        "*Don't forgot to switch to GPU on Colab!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-Tc3ovEyQ9b",
        "colab_type": "text"
      },
      "source": [
        "## Load Your Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR8wtsnp7Dmz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "ccfee02a-6e62-4c3b-d731-bf7609e661fa"
      },
      "source": [
        "# insert where appropriate\n",
        "from sklearn.utils import shuffle\n",
        "X, y = shuffle(X, y)\n",
        "\n",
        "# insert where appropriate\n",
        "model.fit(X,y, epochs=30, validation_split=.2, shuffle=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f4026e6b55b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# insert where appropriate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSpxmzTihiSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "X, y = shuffle(X, y)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkU0pAYCvU8o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "bf51c6ca-5dd5-493a-856a-f93fc860e438"
      },
      "source": [
        "import numpy as np\n",
        "# data = np.load('./sample_data/quickdraw10.npz')\n",
        "# data = np.load('quickdraw10.npz', allow1_pickle=True)\n",
        "data = np.load('quickdraw10 (1).npz', allow_pickle=True)\n",
        "# data = np.load('quickdraw10.npz', allow_pickle = True)\n",
        "# data = np.loadtxt('quickdraw10.npz', delimiter=',')\n",
        "\n",
        "X = data['arr_0']\n",
        "y = data['arr_1']\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 784)\n",
            "(100000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8qsDqdqvHDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['apple',\n",
        " 'anvil',\n",
        " 'airplane',\n",
        " 'banana',\n",
        " 'The Eiffel Tower',\n",
        " 'The Mona Lisa',\n",
        " 'The Great Wall of China',\n",
        " 'alarm clock',\n",
        " 'ant',\n",
        " 'asparagus']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Owbm1EbxvA5A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "022ad432-c648-44d4-9f06-a1f5e421c9e1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,5))\n",
        "start = 0\n",
        "\n",
        "for num, name in enumerate(class_names):\n",
        "    plt.subplot(2,5, num+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(X[start].reshape(28,28), cmap=plt.cm.binary)\n",
        "    plt.xlabel(name)\n",
        "    start += 10000\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb70CbLVyK65",
        "colab_type": "text"
      },
      "source": [
        "## Build Your Baseline Model\n",
        "Some Hints:\n",
        "\n",
        "\n",
        "*  Model should have 784 input values (like mnist)\n",
        "*  Use `sparse_categorical_crossentropy` as your loss function.\n",
        "* You need 10 neurons in your last layer for output\n",
        "* You can add as many hidden layers with as many neurons in them as you like. \n",
        "* The default batchsize should be fine for this exercise.\n",
        "* Limit your model epochs to 30 each time you fit.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hurX3PZnE7c6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import SGD, Adam"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHWblzsMyNkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "                    Dense(5, activation='sigmoid', input_dim=784),\n",
        "                    Dense(5, activation='sigmoid'), \n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# question 5 what does it correspond to?"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAfx2_pUFDva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=SGD(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQeCnUHhG6CF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "bde0acad-6932-47b0-da9b-0e0bc2431e25"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 5)                 3925      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                60        \n",
            "=================================================================\n",
            "Total params: 4,015\n",
            "Trainable params: 4,015\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEZUEuT7Iym4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0822336d-6b48-4262-9b11-7b5b6941ecd1"
      },
      "source": [
        "# insert where appropriate\n",
        "model.fit(X,y, epochs=30, validation_split=.2, shuffle=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.0192 - accuracy: 0.2577 - val_loss: 4.3947 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.7794 - accuracy: 0.4275 - val_loss: 5.2075 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6614 - accuracy: 0.4743 - val_loss: 5.7112 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5668 - accuracy: 0.5147 - val_loss: 6.1101 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4856 - accuracy: 0.5147 - val_loss: 6.3649 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4510 - accuracy: 0.4851 - val_loss: 6.5320 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.3891 - accuracy: 0.5272 - val_loss: 6.8921 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.3494 - accuracy: 0.5393 - val_loss: 7.0974 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.3076 - accuracy: 0.5792 - val_loss: 7.1705 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.2733 - accuracy: 0.5933 - val_loss: 7.2165 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2657 - accuracy: 0.5846 - val_loss: 7.4459 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2363 - accuracy: 0.5979 - val_loss: 7.5189 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2278 - accuracy: 0.6023 - val_loss: 7.8108 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2325 - accuracy: 0.5977 - val_loss: 8.0610 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1961 - accuracy: 0.6069 - val_loss: 7.7994 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1781 - accuracy: 0.6119 - val_loss: 7.8767 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1935 - accuracy: 0.6019 - val_loss: 7.8570 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1960 - accuracy: 0.6022 - val_loss: 8.2826 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1731 - accuracy: 0.6126 - val_loss: 8.2774 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1666 - accuracy: 0.6068 - val_loss: 8.1004 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1728 - accuracy: 0.6161 - val_loss: 8.0531 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1627 - accuracy: 0.6114 - val_loss: 8.4275 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1774 - accuracy: 0.6039 - val_loss: 8.3384 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1683 - accuracy: 0.5908 - val_loss: 8.2156 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1575 - accuracy: 0.6033 - val_loss: 8.2853 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1389 - accuracy: 0.6231 - val_loss: 8.3347 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1438 - accuracy: 0.6241 - val_loss: 8.2450 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1462 - accuracy: 0.6288 - val_loss: 8.3920 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1508 - accuracy: 0.6297 - val_loss: 8.5119 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1381 - accuracy: 0.6356 - val_loss: 8.5805 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa6b21aad68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAhBrcE4yOZe",
        "colab_type": "text"
      },
      "source": [
        "## Change Optimizers\n",
        "Try using the keras `adam` optimizer instead of `sgd` in your model. Visualize the difference in validation loss between the models with different optimizers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFRqucDpGci4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "                    Dense(5, activation='sigmoid', input_dim=784),\n",
        "                    Dense(5, activation='sigmoid'), \n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# question 5 what does it correspond to?"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIW_spOZ0cxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "# model.compile(optimizer=SGD(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f-n7BnPKnKQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "b6c0b08c-1100-48fa-aad2-7a52e3b9e2b2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 5)                 3925      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                60        \n",
            "=================================================================\n",
            "Total params: 4,015\n",
            "Trainable params: 4,015\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGo5KBUKKpBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3536dbbd-afe7-4e02-fc0e-f60f89aeb0b7"
      },
      "source": [
        "# insert where appropriate\n",
        "model.fit(X,y, epochs=30, validation_split=.2, shuffle=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.7235 - accuracy: 0.3718 - val_loss: 6.5351 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4312 - accuracy: 0.4377 - val_loss: 8.2946 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.3262 - accuracy: 0.4818 - val_loss: 9.5891 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2769 - accuracy: 0.5042 - val_loss: 10.8852 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.2509 - accuracy: 0.5432 - val_loss: 11.6883 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1994 - accuracy: 0.5845 - val_loss: 13.4200 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1930 - accuracy: 0.5488 - val_loss: 14.6950 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1773 - accuracy: 0.5688 - val_loss: 16.2472 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1582 - accuracy: 0.5621 - val_loss: 17.8472 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1344 - accuracy: 0.5857 - val_loss: 18.8298 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1340 - accuracy: 0.6028 - val_loss: 19.6182 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1363 - accuracy: 0.5898 - val_loss: 20.4162 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1284 - accuracy: 0.5940 - val_loss: 20.9674 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1120 - accuracy: 0.6144 - val_loss: 21.3534 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0986 - accuracy: 0.6251 - val_loss: 21.6405 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0964 - accuracy: 0.6267 - val_loss: 21.9115 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0810 - accuracy: 0.6359 - val_loss: 21.9907 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0801 - accuracy: 0.6390 - val_loss: 22.0631 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0767 - accuracy: 0.6346 - val_loss: 22.0549 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0697 - accuracy: 0.6399 - val_loss: 22.2157 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0690 - accuracy: 0.6340 - val_loss: 22.5252 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0525 - accuracy: 0.6499 - val_loss: 22.7053 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0495 - accuracy: 0.6568 - val_loss: 22.5007 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0523 - accuracy: 0.6595 - val_loss: 22.6489 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0463 - accuracy: 0.6594 - val_loss: 22.6899 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0494 - accuracy: 0.6629 - val_loss: 23.1038 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0592 - accuracy: 0.6538 - val_loss: 23.1043 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0332 - accuracy: 0.6643 - val_loss: 23.2400 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0470 - accuracy: 0.6595 - val_loss: 23.3539 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0369 - accuracy: 0.6609 - val_loss: 23.3157 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa6a256add8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgZvcEyu0dWb",
        "colab_type": "text"
      },
      "source": [
        "## Optimize Learning Rate\n",
        "Using the optimizer your picked in the previous step, begin tuning the learning rate within that optimizer. Try manually choosing 3-5 learning rate.values. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUQHcjHU1KLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = Adam(learning_rate = 0.01)\n",
        "    \n",
        "# default learning rate: 0.001\n",
        "# low LR = 0.0001 - opt_adam_1\n",
        "# higher LR = 0.01 - opt_adam\n",
        "# default LR = 0.001\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtV7IZDhQh6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# opt_adam: higher LR\n",
        "model = Sequential([\n",
        "                    Dense(5, activation='sigmoid', input_dim=784),\n",
        "                    Dense(5, activation='sigmoid'), \n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OKf2rqVQrnl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1bde2eba-a74a-4846-8f42-860a4af9a680"
      },
      "source": [
        "opt_adam = model.fit(X,y, epochs=30, validation_split=.2, shuffle=True)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.7339 - accuracy: 0.3263 - val_loss: 10.4019 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6046 - accuracy: 0.3716 - val_loss: 11.9586 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5317 - accuracy: 0.3975 - val_loss: 13.2850 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5740 - accuracy: 0.3705 - val_loss: 13.3268 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5791 - accuracy: 0.3844 - val_loss: 14.5508 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5855 - accuracy: 0.3645 - val_loss: 18.3062 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4958 - accuracy: 0.4053 - val_loss: 19.4901 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4663 - accuracy: 0.4178 - val_loss: 18.4971 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4912 - accuracy: 0.4169 - val_loss: 19.8824 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5332 - accuracy: 0.3987 - val_loss: 23.9381 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5449 - accuracy: 0.3820 - val_loss: 23.7152 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.5024 - accuracy: 0.4006 - val_loss: 23.8997 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.4989 - accuracy: 0.4092 - val_loss: 23.6469 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.4886 - accuracy: 0.4103 - val_loss: 23.5793 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5194 - accuracy: 0.3907 - val_loss: 21.8979 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5068 - accuracy: 0.3968 - val_loss: 22.5121 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5059 - accuracy: 0.4001 - val_loss: 21.9829 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4838 - accuracy: 0.4121 - val_loss: 23.0662 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4844 - accuracy: 0.4110 - val_loss: 24.0709 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4793 - accuracy: 0.4097 - val_loss: 23.2592 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5013 - accuracy: 0.3996 - val_loss: 24.0645 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5078 - accuracy: 0.3897 - val_loss: 24.4347 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4677 - accuracy: 0.4138 - val_loss: 25.1780 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.4540 - accuracy: 0.4215 - val_loss: 25.1910 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4325 - accuracy: 0.4267 - val_loss: 25.1245 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.4540 - accuracy: 0.4235 - val_loss: 25.6336 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.4504 - accuracy: 0.4239 - val_loss: 25.2266 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.4397 - accuracy: 0.4205 - val_loss: 24.5302 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.4208 - accuracy: 0.4338 - val_loss: 24.2084 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4288 - accuracy: 0.4291 - val_loss: 24.3221 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecdPCL-FSDkf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8f773196-ee4e-48e9-c272-0f650152b49f"
      },
      "source": [
        "# \n",
        "adam = Adam(learning_rate = 0.001)\n",
        "\n",
        "# opt_adam: higher LR\n",
        "model = Sequential([\n",
        "                    Dense(15, activation='sigmoid', input_dim=784),\n",
        "                    Dense(15, activation='sigmoid'),\n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "opt_adam_1 = model.fit(X,y, epochs=30, validation_split=.2)\n",
        "\n",
        "    \n",
        "# default learning rate: 0.001\n",
        "# low LR = 0.0001 - opt_adam_1\n",
        "# higher LR = 0.01 - opt_adam\n",
        "# default LR = 0.001\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.6007 - accuracy: 0.4836 - val_loss: 1.3014 - val_accuracy: 0.5594\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.2524 - accuracy: 0.5802 - val_loss: 1.2165 - val_accuracy: 0.5935\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1457 - accuracy: 0.6281 - val_loss: 1.1918 - val_accuracy: 0.6055\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0862 - accuracy: 0.6564 - val_loss: 1.0909 - val_accuracy: 0.6603\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0366 - accuracy: 0.6761 - val_loss: 1.0054 - val_accuracy: 0.6797\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0138 - accuracy: 0.6794 - val_loss: 0.9928 - val_accuracy: 0.6863\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9770 - accuracy: 0.6959 - val_loss: 0.9828 - val_accuracy: 0.6953\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9655 - accuracy: 0.6997 - val_loss: 0.9656 - val_accuracy: 0.6955\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9643 - accuracy: 0.7003 - val_loss: 0.9263 - val_accuracy: 0.7161\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9688 - accuracy: 0.6976 - val_loss: 0.9609 - val_accuracy: 0.7002\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9373 - accuracy: 0.7071 - val_loss: 0.9203 - val_accuracy: 0.7157\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9484 - accuracy: 0.7036 - val_loss: 0.9799 - val_accuracy: 0.6899\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9351 - accuracy: 0.7115 - val_loss: 0.9518 - val_accuracy: 0.7023\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9279 - accuracy: 0.7127 - val_loss: 0.9465 - val_accuracy: 0.6984\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9241 - accuracy: 0.7185 - val_loss: 0.9124 - val_accuracy: 0.7161\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9161 - accuracy: 0.7206 - val_loss: 0.9074 - val_accuracy: 0.7265\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9183 - accuracy: 0.7199 - val_loss: 0.9115 - val_accuracy: 0.7152\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9162 - accuracy: 0.7154 - val_loss: 0.9083 - val_accuracy: 0.7182\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9020 - accuracy: 0.7225 - val_loss: 0.9021 - val_accuracy: 0.7196\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9164 - accuracy: 0.7189 - val_loss: 0.9244 - val_accuracy: 0.7113\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8975 - accuracy: 0.7264 - val_loss: 0.9067 - val_accuracy: 0.7248\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9040 - accuracy: 0.7245 - val_loss: 0.9055 - val_accuracy: 0.7247\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9056 - accuracy: 0.7253 - val_loss: 0.9010 - val_accuracy: 0.7201\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8904 - accuracy: 0.7258 - val_loss: 0.8953 - val_accuracy: 0.7250\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8791 - accuracy: 0.7325 - val_loss: 0.9105 - val_accuracy: 0.7201\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8947 - accuracy: 0.7273 - val_loss: 0.9127 - val_accuracy: 0.7192\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8893 - accuracy: 0.7287 - val_loss: 0.8898 - val_accuracy: 0.7219\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8824 - accuracy: 0.7281 - val_loss: 0.8750 - val_accuracy: 0.7301\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8756 - accuracy: 0.7304 - val_loss: 0.8886 - val_accuracy: 0.7221\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8755 - accuracy: 0.7314 - val_loss: 0.8820 - val_accuracy: 0.7260\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIDvZxi2miRc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c346f04-a35b-44d8-fd61-8d203d1b95ee"
      },
      "source": [
        "# \n",
        "adam = Adam(learning_rate = 0.001)\n",
        "\n",
        "# opt_adam: higher LR\n",
        "model = Sequential([\n",
        "                    Dense(20, activation='sigmoid', input_dim=784),\n",
        "                    Dense(15, activation='sigmoid'),\n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "opt_adam_1 = model.fit(X,y, epochs=30, validation_split=.2)\n",
        "\n",
        "    \n",
        "# default learning rate: 0.001\n",
        "# low LR = 0.0001 - opt_adam_1\n",
        "# higher LR = 0.01 - opt_adam\n",
        "# default LR = 0.001\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.5246 - accuracy: 0.5179 - val_loss: 1.2281 - val_accuracy: 0.6144\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1222 - accuracy: 0.6453 - val_loss: 1.0612 - val_accuracy: 0.6654\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0187 - accuracy: 0.6749 - val_loss: 0.9627 - val_accuracy: 0.6985\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9725 - accuracy: 0.6926 - val_loss: 0.9651 - val_accuracy: 0.6934\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9486 - accuracy: 0.7018 - val_loss: 0.9330 - val_accuracy: 0.7070\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9157 - accuracy: 0.7134 - val_loss: 0.9192 - val_accuracy: 0.7127\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9136 - accuracy: 0.7118 - val_loss: 0.9104 - val_accuracy: 0.7111\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9030 - accuracy: 0.7152 - val_loss: 0.9329 - val_accuracy: 0.7028\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9002 - accuracy: 0.7158 - val_loss: 0.8975 - val_accuracy: 0.7171\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8790 - accuracy: 0.7232 - val_loss: 0.9006 - val_accuracy: 0.7164\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8955 - accuracy: 0.7191 - val_loss: 0.9050 - val_accuracy: 0.7193\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8590 - accuracy: 0.7317 - val_loss: 0.8656 - val_accuracy: 0.7350\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8699 - accuracy: 0.7308 - val_loss: 0.8619 - val_accuracy: 0.7314\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8432 - accuracy: 0.7401 - val_loss: 0.8433 - val_accuracy: 0.7424\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8484 - accuracy: 0.7379 - val_loss: 0.8807 - val_accuracy: 0.7265\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8438 - accuracy: 0.7378 - val_loss: 0.8530 - val_accuracy: 0.7351\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8435 - accuracy: 0.7345 - val_loss: 0.8313 - val_accuracy: 0.7424\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8276 - accuracy: 0.7412 - val_loss: 0.8311 - val_accuracy: 0.7380\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8290 - accuracy: 0.7399 - val_loss: 0.8504 - val_accuracy: 0.7276\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8249 - accuracy: 0.7425 - val_loss: 0.8191 - val_accuracy: 0.7467\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8096 - accuracy: 0.7480 - val_loss: 0.8259 - val_accuracy: 0.7381\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8173 - accuracy: 0.7434 - val_loss: 0.8353 - val_accuracy: 0.7340\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8159 - accuracy: 0.7441 - val_loss: 0.8321 - val_accuracy: 0.7389\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8160 - accuracy: 0.7461 - val_loss: 0.8323 - val_accuracy: 0.7369\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8111 - accuracy: 0.7465 - val_loss: 0.8250 - val_accuracy: 0.7416\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8073 - accuracy: 0.7476 - val_loss: 0.8123 - val_accuracy: 0.7444\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8064 - accuracy: 0.7461 - val_loss: 0.8160 - val_accuracy: 0.7415\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8072 - accuracy: 0.7471 - val_loss: 0.8404 - val_accuracy: 0.7408\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8144 - accuracy: 0.7467 - val_loss: 0.8060 - val_accuracy: 0.7480\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8110 - accuracy: 0.7476 - val_loss: 0.8137 - val_accuracy: 0.7450\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DARrHWaGnMDD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "outputId": "20f73159-20c3-4abb-a0ad-74a2d76d20d3"
      },
      "source": [
        "# \n",
        "adam = Adam(learning_rate = 0.001)\n",
        "\n",
        "# opt_adam: higher LR\n",
        "model = Sequential([\n",
        "                    Dense(30, activation='sigmoid', input_dim=784),\n",
        "                    Dense(20, activation='sigmoid'),\n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "opt_adam_1 = model.fit(X,y, epochs=30, validation_split=.2)\n",
        "\n",
        "    \n",
        "# default learning rate: 0.001\n",
        "# low LR = 0.0001 - opt_adam_1\n",
        "# higher LR = 0.01 - opt_adam\n",
        "# default LR = 0.001\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.3780 - accuracy: 0.5796 - val_loss: 1.0538 - val_accuracy: 0.6719\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0163 - accuracy: 0.6787 - val_loss: 0.9842 - val_accuracy: 0.6893\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9681 - accuracy: 0.6918 - val_loss: 0.9429 - val_accuracy: 0.7016\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9363 - accuracy: 0.7061 - val_loss: 0.8980 - val_accuracy: 0.7210\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.9009 - accuracy: 0.7181 - val_loss: 0.8859 - val_accuracy: 0.7253\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8841 - accuracy: 0.7229 - val_loss: 0.8663 - val_accuracy: 0.7243\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8760 - accuracy: 0.7278 - val_loss: 0.8854 - val_accuracy: 0.7191\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8734 - accuracy: 0.7265 - val_loss: 0.8810 - val_accuracy: 0.7204\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8671 - accuracy: 0.7279 - val_loss: 0.8430 - val_accuracy: 0.7415\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8550 - accuracy: 0.7331 - val_loss: 0.8546 - val_accuracy: 0.7310\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8304 - accuracy: 0.7404 - val_loss: 0.8422 - val_accuracy: 0.7368\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8193 - accuracy: 0.7458 - val_loss: 0.8238 - val_accuracy: 0.7420\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8104 - accuracy: 0.7484 - val_loss: 0.8081 - val_accuracy: 0.7444\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8063 - accuracy: 0.7500 - val_loss: 0.7949 - val_accuracy: 0.7516\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8017 - accuracy: 0.7496 - val_loss: 0.8029 - val_accuracy: 0.7497\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8052 - accuracy: 0.7490 - val_loss: 0.8239 - val_accuracy: 0.7420\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8000 - accuracy: 0.7498 - val_loss: 0.8035 - val_accuracy: 0.7456\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8031 - accuracy: 0.7488 - val_loss: 0.8193 - val_accuracy: 0.7440\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8041 - accuracy: 0.7489 - val_loss: 0.8105 - val_accuracy: 0.7440\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.7813 - accuracy: 0.7576 - val_loss: 0.7709 - val_accuracy: 0.7596\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.7674 - accuracy: 0.7633 - val_loss: 0.7868 - val_accuracy: 0.7524\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.7749 - accuracy: 0.7591 - val_loss: 0.7681 - val_accuracy: 0.7612\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.7691 - accuracy: 0.7610 - val_loss: 0.7719 - val_accuracy: 0.7578\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.7670 - accuracy: 0.7589 - val_loss: 0.7714 - val_accuracy: 0.7591\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.7644 - accuracy: 0.7619 - val_loss: 0.7759 - val_accuracy: 0.7584\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.7746 - accuracy: 0.7583 - val_loss: 0.7802 - val_accuracy: 0.7594\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.7609 - accuracy: 0.7638 - val_loss: 0.7639 - val_accuracy: 0.7618\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.7674 - accuracy: 0.7587 - val_loss: 0.7629 - val_accuracy: 0.7580\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.7630 - accuracy: 0.7614 - val_loss: 0.7781 - val_accuracy: 0.7566\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.7595 - accuracy: 0.7621 - val_loss: 0.7709 - val_accuracy: 0.7570\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STqqE88PoBfH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "outputId": "d3e82bb0-1cf9-4ee9-d5e2-989cd7608d8f"
      },
      "source": [
        "# \n",
        "adam = Adam(learning_rate = 0.001)\n",
        "\n",
        "# opt_adam: higher LR\n",
        "model = Sequential([\n",
        "                    Dense(30, activation='sigmoid', input_dim=784),\n",
        "                    Dense(20, activation='sigmoid'),\n",
        "                    Dense(20, activation='sigmoid'),\n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "opt_adam_1 = model.nnfit(X,y, epochs=30, validation_split=.2)\n",
        "\n",
        "    \n",
        "# default learning rate: 0.001\n",
        "# low LR = 0.0001 - opt_adam_1\n",
        "# higher LR = 0.01 - opt_adam\n",
        "# default LR = 0.001\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.5489 - accuracy: 0.4579 - val_loss: 1.3212 - val_accuracy: 0.5319\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.2503 - accuracy: 0.5691 - val_loss: 1.1597 - val_accuracy: 0.6181\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1000 - accuracy: 0.6439 - val_loss: 1.0310 - val_accuracy: 0.6744\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0197 - accuracy: 0.6755 - val_loss: 1.0143 - val_accuracy: 0.6636\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9765 - accuracy: 0.6874 - val_loss: 0.9420 - val_accuracy: 0.7018\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9317 - accuracy: 0.7040 - val_loss: 0.9097 - val_accuracy: 0.7095\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.9181 - accuracy: 0.7078 - val_loss: 0.9326 - val_accuracy: 0.7043\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8962 - accuracy: 0.7191 - val_loss: 0.8825 - val_accuracy: 0.7223\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8727 - accuracy: 0.7246 - val_loss: 0.8564 - val_accuracy: 0.7278\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8626 - accuracy: 0.7281 - val_loss: 0.8532 - val_accuracy: 0.7300\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8445 - accuracy: 0.7340 - val_loss: 0.8421 - val_accuracy: 0.7406\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8514 - accuracy: 0.7350 - val_loss: 0.8526 - val_accuracy: 0.7339\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8419 - accuracy: 0.7373 - val_loss: 0.8453 - val_accuracy: 0.7351\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8243 - accuracy: 0.7429 - val_loss: 0.8390 - val_accuracy: 0.7345\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8166 - accuracy: 0.7405 - val_loss: 0.8126 - val_accuracy: 0.7434\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8113 - accuracy: 0.7442 - val_loss: 0.8288 - val_accuracy: 0.7359\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8115 - accuracy: 0.7415 - val_loss: 0.8350 - val_accuracy: 0.7325\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8133 - accuracy: 0.7420 - val_loss: 0.8342 - val_accuracy: 0.7369\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8121 - accuracy: 0.7447 - val_loss: 0.8045 - val_accuracy: 0.7487\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8000 - accuracy: 0.7486 - val_loss: 0.8037 - val_accuracy: 0.7466\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.7929 - accuracy: 0.7520 - val_loss: 0.7906 - val_accuracy: 0.7469\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.7770 - accuracy: 0.7540 - val_loss: 0.7878 - val_accuracy: 0.7501\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.7810 - accuracy: 0.7550 - val_loss: 0.7854 - val_accuracy: 0.7515\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.7777 - accuracy: 0.7555 - val_loss: 0.7841 - val_accuracy: 0.7522\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.7647 - accuracy: 0.7583 - val_loss: 0.7688 - val_accuracy: 0.7570\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.7636 - accuracy: 0.7602 - val_loss: 0.7719 - val_accuracy: 0.7545\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.7557 - accuracy: 0.7623 - val_loss: 0.7670 - val_accuracy: 0.7602\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.7511 - accuracy: 0.7645 - val_loss: 0.7701 - val_accuracy: 0.7584\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.7489 - accuracy: 0.7648 - val_loss: 0.7599 - val_accuracy: 0.7593\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.7499 - accuracy: 0.7637 - val_loss: 0.7641 - val_accuracy: 0.7578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFOxUteTTke-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b06b8a0-2936-4938-e2ec-b0bf881cb2e7"
      },
      "source": [
        "# opt_adam_2\n",
        "adam = Adam(learning_rate = 0.1)\n",
        "\n",
        "# opt_adam: higher LR\n",
        "model = Sequential([\n",
        "                    Dense(5, activation='sigmoid', input_dim=784),\n",
        "                    Dense(5, activation='sigmoid'), \n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "opt_adam_2 = model.fit(X,y, epochs=30, validation_split=.2, shuffle=True)\n",
        "\n",
        "    \n",
        "# default learning rate: 0.001\n",
        "# low LR = 0.0001 - opt_adam_1\n",
        "# higher LR = 0.01 - opt_adam\n",
        "# higher LR = 0.1 - opt_adam_2\n",
        "# default LR = 0.001\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.0532 - accuracy: 0.1465 - val_loss: 11.6315 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 2.0256 - accuracy: 0.1571 - val_loss: 14.2103 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8724 - accuracy: 0.2365 - val_loss: 15.3087 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.9301 - accuracy: 0.2036 - val_loss: 16.6959 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8586 - accuracy: 0.2296 - val_loss: 17.9941 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8503 - accuracy: 0.2384 - val_loss: 19.3620 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8510 - accuracy: 0.2353 - val_loss: 20.9761 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.8750 - accuracy: 0.2192 - val_loss: 22.0545 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8722 - accuracy: 0.2198 - val_loss: 22.8579 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8724 - accuracy: 0.2190 - val_loss: 23.8028 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8723 - accuracy: 0.2212 - val_loss: 24.2545 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8897 - accuracy: 0.2155 - val_loss: 24.6504 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8805 - accuracy: 0.2184 - val_loss: 24.9519 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8554 - accuracy: 0.2291 - val_loss: 25.1950 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8443 - accuracy: 0.2336 - val_loss: 25.2626 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8432 - accuracy: 0.2354 - val_loss: 25.5088 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8434 - accuracy: 0.2349 - val_loss: 25.5291 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8540 - accuracy: 0.2275 - val_loss: 25.3507 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8594 - accuracy: 0.2252 - val_loss: 25.4658 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8534 - accuracy: 0.2283 - val_loss: 25.7328 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8476 - accuracy: 0.2340 - val_loss: 25.6845 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8474 - accuracy: 0.2359 - val_loss: 26.0002 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8548 - accuracy: 0.2332 - val_loss: 25.6214 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8654 - accuracy: 0.2231 - val_loss: 25.3707 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8542 - accuracy: 0.2296 - val_loss: 26.0596 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8429 - accuracy: 0.2386 - val_loss: 26.0856 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8400 - accuracy: 0.2369 - val_loss: 26.1708 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8400 - accuracy: 0.2352 - val_loss: 26.1906 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8403 - accuracy: 0.2353 - val_loss: 26.3311 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8431 - accuracy: 0.2381 - val_loss: 26.4935 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWjenJqeVzOe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2b4e74d1-717d-4770-c344-0f996b829099"
      },
      "source": [
        "# opt_adam_3\n",
        "adam = Adam(learning_rate = 0.0009)\n",
        "\n",
        "# opt_adam: higher LR\n",
        "model = Sequential([\n",
        "                    Dense(5, activation='sigmoid', input_dim=784),\n",
        "                    Dense(5, activation='sigmoid'), \n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "opt_adam_2 = model.fit(X,y, epochs=30, validation_split=.2, shuffle=True)\n",
        "\n",
        "    \n",
        "# default learning rate: 0.001\n",
        "# low LR = 0.0001 - opt_adam_1\n",
        "# higher LR = 0.01 - opt_adam\n",
        "# higher LR = 0.1 - opt_adam_2\n",
        "# higher LR = 0.0009 - opt_adam_3\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.8315 - accuracy: 0.3395 - val_loss: 5.5827 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4695 - accuracy: 0.4315 - val_loss: 7.5044 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.3546 - accuracy: 0.4669 - val_loss: 8.7384 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.3022 - accuracy: 0.4898 - val_loss: 9.6577 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.2941 - accuracy: 0.5015 - val_loss: 11.2792 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2829 - accuracy: 0.5111 - val_loss: 11.9895 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2670 - accuracy: 0.5117 - val_loss: 13.2801 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2688 - accuracy: 0.5051 - val_loss: 14.5620 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2444 - accuracy: 0.5190 - val_loss: 15.7317 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2232 - accuracy: 0.5323 - val_loss: 16.8842 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2036 - accuracy: 0.5414 - val_loss: 18.2551 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.2014 - accuracy: 0.5480 - val_loss: 18.6072 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1892 - accuracy: 0.5530 - val_loss: 19.1028 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1756 - accuracy: 0.5487 - val_loss: 19.3540 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1657 - accuracy: 0.5549 - val_loss: 19.8111 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1516 - accuracy: 0.5526 - val_loss: 20.1917 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1532 - accuracy: 0.5663 - val_loss: 19.9020 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1294 - accuracy: 0.5646 - val_loss: 20.6208 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1401 - accuracy: 0.5705 - val_loss: 21.3076 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1306 - accuracy: 0.5695 - val_loss: 20.8084 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1197 - accuracy: 0.5726 - val_loss: 21.0215 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1314 - accuracy: 0.5707 - val_loss: 21.2256 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1295 - accuracy: 0.5742 - val_loss: 21.2535 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1099 - accuracy: 0.5816 - val_loss: 21.4282 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1079 - accuracy: 0.5775 - val_loss: 21.4195 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1061 - accuracy: 0.5910 - val_loss: 20.8682 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1119 - accuracy: 0.5856 - val_loss: 21.3000 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0909 - accuracy: 0.5868 - val_loss: 21.5734 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0855 - accuracy: 0.5944 - val_loss: 21.6412 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0826 - accuracy: 0.6036 - val_loss: 22.2478 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcMegS0WZAAc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "132e3d6c-5852-4715-d11b-13d06ba4ad5b"
      },
      "source": [
        "# opt_adam_3\n",
        "adam = Adam(learning_rate = 0.002)\n",
        "\n",
        "# opt_adam: higher LR\n",
        "model = Sequential([\n",
        "                    Dense(5, activation='sigmoid', input_dim=784),\n",
        "                    Dense(5, activation='sigmoid'), \n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "opt_adam_2 = model.fit(X,y, epochs=30, validation_split=.2, shuffle=True)\n",
        "\n",
        "    \n",
        "# default learning rate: 0.001\n",
        "# low LR = 0.0001 - opt_adam_1\n",
        "# higher LR = 0.01 - opt_adam\n",
        "# higher LR = 0.1 - opt_adam_2\n",
        "# higher LR = 0.0009 - opt_adam_3\n",
        "# higher LR = 0.002 - opt_adam_4\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.6821 - accuracy: 0.3880 - val_loss: 7.8082 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.3819 - accuracy: 0.4919 - val_loss: 9.5937 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.2706 - accuracy: 0.5075 - val_loss: 10.7110 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.2329 - accuracy: 0.5044 - val_loss: 11.8912 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2187 - accuracy: 0.5295 - val_loss: 13.2343 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1943 - accuracy: 0.5264 - val_loss: 14.4867 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1980 - accuracy: 0.5376 - val_loss: 16.2024 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1924 - accuracy: 0.5230 - val_loss: 17.4201 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1657 - accuracy: 0.5530 - val_loss: 18.7786 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1698 - accuracy: 0.5523 - val_loss: 19.4025 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1561 - accuracy: 0.5710 - val_loss: 19.9318 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1541 - accuracy: 0.5774 - val_loss: 20.8605 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1514 - accuracy: 0.5829 - val_loss: 21.5636 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1466 - accuracy: 0.5803 - val_loss: 20.8531 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1729 - accuracy: 0.5641 - val_loss: 21.2150 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1265 - accuracy: 0.5949 - val_loss: 22.2927 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1243 - accuracy: 0.5937 - val_loss: 22.8840 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1251 - accuracy: 0.5895 - val_loss: 22.1168 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1085 - accuracy: 0.6030 - val_loss: 22.3781 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0871 - accuracy: 0.6112 - val_loss: 22.9713 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0860 - accuracy: 0.6211 - val_loss: 23.1130 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0875 - accuracy: 0.6287 - val_loss: 22.9288 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0688 - accuracy: 0.6330 - val_loss: 23.1861 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0745 - accuracy: 0.6234 - val_loss: 23.2599 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0529 - accuracy: 0.6312 - val_loss: 23.1088 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0456 - accuracy: 0.6370 - val_loss: 23.2674 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0393 - accuracy: 0.6404 - val_loss: 22.8911 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0455 - accuracy: 0.6395 - val_loss: 22.8858 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0484 - accuracy: 0.6437 - val_loss: 22.8753 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0510 - accuracy: 0.6417 - val_loss: 22.5614 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etQwDkVFfojE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e6fcc450-55c4-47c2-ae09-7f1ad6aeafa9"
      },
      "source": [
        "# opt_adam_3\n",
        "adam = Adam(learning_rate = 0.0011)\n",
        "\n",
        "# opt_adam: higher LR\n",
        "model = Sequential([\n",
        "                    Dense(5, activation='sigmoid', input_dim=784),\n",
        "                    Dense(5, activation='sigmoid'), \n",
        "                    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "opt_adam_2 = model.fit(X,y, epochs=30, validation_split=.2, shuffle=True)\n",
        "\n",
        "    \n",
        "# default learning rate: 0.001\n",
        "# low LR = 0.0001 - opt_adam_1\n",
        "# higher LR = 0.01 - opt_adam\n",
        "# higher LR = 0.1 - opt_adam_2\n",
        "# higher LR = 0.0009 - opt_adam_3\n",
        "# higher LR = 0.002 - opt_adam_4\n",
        "# higher LR = 0.0011 - opt_adam_5\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8076 - accuracy: 0.3506 - val_loss: 6.2999 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4819 - accuracy: 0.4657 - val_loss: 8.3733 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.3397 - accuracy: 0.4990 - val_loss: 9.4179 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2866 - accuracy: 0.5299 - val_loss: 10.8773 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2512 - accuracy: 0.5468 - val_loss: 11.9803 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.2122 - accuracy: 0.5684 - val_loss: 13.5987 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1809 - accuracy: 0.5961 - val_loss: 14.7170 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1803 - accuracy: 0.5971 - val_loss: 15.8592 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1650 - accuracy: 0.6019 - val_loss: 17.6781 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1438 - accuracy: 0.6153 - val_loss: 18.5319 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1214 - accuracy: 0.6287 - val_loss: 19.5202 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.1170 - accuracy: 0.6304 - val_loss: 20.2870 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1054 - accuracy: 0.6309 - val_loss: 20.8099 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.1018 - accuracy: 0.6366 - val_loss: 20.5380 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0857 - accuracy: 0.6408 - val_loss: 21.5427 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0709 - accuracy: 0.6471 - val_loss: 20.3062 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0764 - accuracy: 0.6376 - val_loss: 20.7917 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0608 - accuracy: 0.6490 - val_loss: 21.7456 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0706 - accuracy: 0.6356 - val_loss: 21.7068 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0620 - accuracy: 0.6363 - val_loss: 21.7062 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0652 - accuracy: 0.6382 - val_loss: 21.8446 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0546 - accuracy: 0.6488 - val_loss: 22.0511 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0537 - accuracy: 0.6502 - val_loss: 21.3442 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0459 - accuracy: 0.6566 - val_loss: 22.2366 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0419 - accuracy: 0.6546 - val_loss: 22.1501 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0449 - accuracy: 0.6490 - val_loss: 22.6789 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0346 - accuracy: 0.6511 - val_loss: 21.9387 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0433 - accuracy: 0.6442 - val_loss: 22.8326 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/30\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0334 - accuracy: 0.6486 - val_loss: 22.4939 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/30\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0215 - accuracy: 0.6564 - val_loss: 22.8996 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUr1Y2DN1VJ-",
        "colab_type": "text"
      },
      "source": [
        "## Save Your Best Performing Model\n",
        "\n",
        "Practice saving the weights and architecture information of your best performing model. Reference the TensorFlow API documentation [here](https://www.tensorflow.org/tutorials/keras/save_and_load#savedmodel_format)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjyJaJ9w1Tu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJrbh3qryi4w",
        "colab_type": "text"
      },
      "source": [
        "### Additional Written Tasks:\n",
        "In this section, you will need to search for resources: \n",
        "1. Investigate the various [loss functions](https://www.tensorflow.org/api_docs/python/tf/keras/losses). Which is best suited for the task at hand (predicting 1 / 0) and why? \n",
        "2. What is the difference between a loss function and a metric? Why might we need both in Keras? \n",
        "3. Investigate the various [optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers). Stochastic Gradient Descent (`sgd`) is not the learning algorithm dejour anyone. Why is that? What do newer optimizers such as `adam` have to offer? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzs4fd-RynDd",
        "colab_type": "text"
      },
      "source": [
        "## Stretch Goals: \n",
        "\n",
        "- Research convolutional neural networks and try including convolution layers in your network.\n",
        "- Pick two classes and make QuickDraw a binary classification problem, how does your model architecture change?\n",
        "- Implement Cross Validation model evaluation on your Quickdraw implementation \n",
        "\n",
        "Watch some more videos on Gradient Descent:\n",
        "- [Gradient Descent, Step-by-Step](https://www.youtube.com/watch?v=sDv4f4s2SB8)  by StatQuest w/ Josh Starmer. This will help you understand the gradient descent based optimization that happens underneath the hood of neural networks. It uses a non-neural network example, which I believe is a gentler introduction. You will hear me refer to this technique as \"vanilla\" gradient descent. \n",
        "- [Stochastic Gradient Descent, Clearly Explained!!!](https://www.youtube.com/watch?v=vMh0zPT0tLI) by StatQuest w/ Josh Starmer. This builds on the techniques in the previous video.  This technique is the one that is actually implemented inside modern 'nets. \n",
        "- [Siraj Raval the evolution of gradient descent](https://www.youtube.com/watch?v=nhqo0u1a6fw)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g649u1eo1R9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue6ZvwoqmYmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}